{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunker\n",
    "\n",
    "# Group: AlphaBetaBet\n",
    "\n",
    "## 1. default program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from default import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Run the default solution on dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [00:01<00:00, 542.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMTaggerModel(\n",
      "  (word_embeddings): Embedding(9675, 128)\n",
      "  (lstm): LSTM(128, 64)\n",
      "  (hidden2tag): Linear(in_features=64, out_features=22, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chunker = LSTMTagger(os.path.join('../data', 'train.txt.gz'), os.path.join('../data', 'chunker'), '.tar')\n",
    "decoder_output = chunker.decode('../data/input/dev.txt')\n",
    "print(chunker.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Evaluate the default output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 23663 tokens with 11896 phrases; found: 11672 phrases; correct: 8568.\n",
      "accuracy:  84.35%; (non-O)\n",
      "accuracy:  85.65%; precision:  73.41%; recall:  72.02%; FB1:  72.71\n",
      "             ADJP: precision:  36.49%; recall:  11.95%; FB1:  18.00  74\n",
      "             ADVP: precision:  71.36%; recall:  39.45%; FB1:  50.81  220\n",
      "            CONJP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "             INTJ: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "               NP: precision:  70.33%; recall:  76.80%; FB1:  73.42  6811\n",
      "               PP: precision:  92.40%; recall:  87.14%; FB1:  89.69  2302\n",
      "              PRT: precision:  65.00%; recall:  57.78%; FB1:  61.18  40\n",
      "             SBAR: precision:  84.62%; recall:  41.77%; FB1:  55.93  117\n",
      "               VP: precision:  63.66%; recall:  58.25%; FB1:  60.83  2108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(73.40644276901988, 72.02420981842637, 72.70875763747455)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_output = [ output for sent in decoder_output for output in sent ]\n",
    "import conlleval\n",
    "true_seqs = []\n",
    "with open(os.path.join('../data','reference','dev.out')) as r:\n",
    "    for sent in conlleval.read_file(r):\n",
    "        true_seqs += sent.split()\n",
    "conlleval.evaluate(true_seqs, flat_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline Model: implement a semi-character RNN to deal with noisy input\n",
    "\n",
    "In the dev and test data any unseen words will be replaced with the [UNK] token (which stands for unknown word). However, any misspelling word will be replaced with the [UNK] token even though its corrected version should have been trained. \n",
    "\n",
    "The semi-character RNN creates a character level representation of the word to help with this problem. The idea is to use semi-character representation to provide more infomation about noisy words. \n",
    "\n",
    "### 2.1 Create a character level representation of the word\n",
    "Create three separated sub-vectors for character level representation of word\n",
    "   - the first vector is one-hot encode vector of first character\n",
    "   - the second vector is a bag of characters of the word without the initial and final positions (count the frequencies of middle characters)\n",
    "   - the third vector is one hot vector of last character\n",
    "\n",
    "### 2.2 Modify LSTMTaggerModel Class\n",
    "1. change the input size of LSTM model (embedding_dim + 3 * len(string.printable)) because the semi-character representation is added to input of LSTM cell\n",
    "2. modify forward function for the input to LSTM model: concatenate word embedding with semi-character vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunker_baseline import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Train the model\n",
    "Train the model over 10 epoches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8936/8936 [02:56<00:00, 50.53it/s]\n",
      "saving model file: ../data/chunker0.tar\n",
      "100%|██████████| 8936/8936 [02:55<00:00, 51.05it/s]\n",
      "saving model file: ../data/chunker1.tar\n",
      "100%|██████████| 8936/8936 [02:51<00:00, 52.18it/s]\n",
      "saving model file: ../data/chunker2.tar\n",
      "100%|██████████| 8936/8936 [03:03<00:00, 48.65it/s]\n",
      "saving model file: ../data/chunker3.tar\n",
      "100%|██████████| 8936/8936 [03:35<00:00, 41.41it/s]\n",
      "saving model file: ../data/chunker4.tar\n",
      "100%|██████████| 8936/8936 [02:52<00:00, 51.84it/s]\n",
      "saving model file: ../data/chunker5.tar\n",
      "100%|██████████| 8936/8936 [03:48<00:00, 39.07it/s]\n",
      "saving model file: ../data/chunker6.tar\n",
      "100%|██████████| 8936/8936 [1:15:39<00:00,  1.97it/s]    \n",
      "saving model file: ../data/chunker7.tar\n",
      "100%|██████████| 8936/8936 [14:06<00:00, 10.55it/s]   \n",
      "saving model file: ../data/chunker8.tar\n",
      "100%|██████████| 8936/8936 [02:51<00:00, 52.03it/s]\n",
      "saving model file: ../data/chunker.tar\n",
      "100%|██████████| 1027/1027 [00:04<00:00, 220.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMTaggerModel(\n",
      "  (word_embeddings): Embedding(9675, 128)\n",
      "  (lstm): LSTM(428, 64)\n",
      "  (hidden2tag): Linear(in_features=64, out_features=22, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "chunker = LSTMTagger(os.path.join('../data', 'train.txt.gz'), os.path.join('../data', 'chunker'), '.tar')\n",
    "chunker.train()\n",
    "decoder_output = chunker.decode('../data/input/dev.txt')\n",
    "print(chunker.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluate the dev output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 23663 tokens with 11896 phrases; found: 11894 phrases; correct: 9161.\n",
      "accuracy:  86.83%; (non-O)\n",
      "accuracy:  87.82%; precision:  77.02%; recall:  77.01%; FB1:  77.02\n",
      "             ADJP: precision:  46.07%; recall:  18.14%; FB1:  26.03  89\n",
      "             ADVP: precision:  66.79%; recall:  46.48%; FB1:  54.81  277\n",
      "            CONJP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "             INTJ: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "               NP: precision:  75.30%; recall:  80.28%; FB1:  77.71  6649\n",
      "               PP: precision:  91.55%; recall:  88.37%; FB1:  89.93  2356\n",
      "              PRT: precision:  69.44%; recall:  55.56%; FB1:  61.73  36\n",
      "             SBAR: precision:  85.60%; recall:  45.15%; FB1:  59.12  125\n",
      "               VP: precision:  69.39%; recall:  71.14%; FB1:  70.25  2362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(77.02202791323356, 77.00907868190988, 77.01555275325767)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_output = [ output for sent in decoder_output for output in sent ]\n",
    "import conlleval\n",
    "true_seqs = []\n",
    "with open(os.path.join('../data','reference','dev.out')) as r:\n",
    "    for sent in conlleval.read_file(r):\n",
    "        true_seqs += sent.split()\n",
    "conlleval.evaluate(true_seqs, flat_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Improved Model: add the POS tag as feature\n",
    "\n",
    "The idea is to find the way to decide the chunk tag of [UNK] better. In section 2, the character level representation of a noisy word has been taken into account. In this section, we manage to improve the accuracy by capitalizing on the part-of-speech(POS) tags. The idea is to concatenate one-hot encoding of POS tags with both word embedding and semi-character representation as input to LSTM cell. \n",
    "\n",
    "### 3.1 Create pos_to_ix dictionary in class LSTMTagger\n",
    "Create a HashTable called pos_to_ix to map one of 44 unique POS tags to an unique index. \n",
    "\n",
    "### 3.2 pos encoding function (create a one-hot encode vector for POS tag)\n",
    "1. create the one-hot encoding vecor for each POS tag of each word based on the pos tag index\n",
    "2. stack all tags in a sentence \n",
    "\n",
    "### 3.3 Modify LSTMTaggerModel Class\n",
    "1. change the input size of LSTM model (embedding_dim + 3 * len(string.printable) + pos_size)\n",
    "2. modify forward function for the input tensor to LSTM model: concatenate word embedding with semi-character representation and pos tag vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunker import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Train the model\n",
    "Train the model over 10 epoches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8936/8936 [03:30<00:00, 42.38it/s]\n",
      "saving model file: ../data/chunker0.tar\n",
      "100%|██████████| 8936/8936 [03:18<00:00, 45.00it/s]\n",
      "saving model file: ../data/chunker1.tar\n",
      "100%|██████████| 8936/8936 [03:06<00:00, 47.84it/s]\n",
      "saving model file: ../data/chunker2.tar\n",
      "100%|██████████| 8936/8936 [03:00<00:00, 49.60it/s]\n",
      "saving model file: ../data/chunker3.tar\n",
      "100%|██████████| 8936/8936 [03:14<00:00, 45.87it/s]\n",
      "saving model file: ../data/chunker4.tar\n",
      "100%|██████████| 8936/8936 [03:09<00:00, 47.09it/s]\n",
      "saving model file: ../data/chunker5.tar\n",
      "100%|██████████| 8936/8936 [03:05<00:00, 48.09it/s]\n",
      "saving model file: ../data/chunker6.tar\n",
      "100%|██████████| 8936/8936 [02:53<00:00, 51.63it/s]\n",
      "saving model file: ../data/chunker7.tar\n",
      "100%|██████████| 8936/8936 [02:53<00:00, 51.46it/s]\n",
      "saving model file: ../data/chunker8.tar\n",
      "100%|██████████| 8936/8936 [03:01<00:00, 49.19it/s]\n",
      "saving model file: ../data/chunker.tar\n",
      "100%|██████████| 1027/1027 [00:04<00:00, 206.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMTaggerModel(\n",
      "  (word_embeddings): Embedding(9675, 128)\n",
      "  (lstm): LSTM(472, 64)\n",
      "  (hidden2tag): Linear(in_features=64, out_features=22, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chunker = LSTMTagger(os.path.join('../data', 'train.txt.gz'), os.path.join('../data', 'chunker'), '.tar')\n",
    "chunker.train() \n",
    "decoder_output = chunker.decode('../data/input/dev.txt')\n",
    "print(chunker.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Evaluate the dev output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 23663 tokens with 11896 phrases; found: 12331 phrases; correct: 10329.\n",
      "accuracy:  91.51%; (non-O)\n",
      "accuracy:  92.03%; precision:  83.76%; recall:  86.83%; FB1:  85.27\n",
      "             ADJP: precision:  47.17%; recall:  33.19%; FB1:  38.96  159\n",
      "             ADVP: precision:  61.70%; recall:  65.58%; FB1:  63.58  423\n",
      "            CONJP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "             INTJ: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "               NP: precision:  85.45%; recall:  89.56%; FB1:  87.46  6537\n",
      "               PP: precision:  91.03%; recall:  91.93%; FB1:  91.48  2465\n",
      "              PRT: precision:  66.67%; recall:  62.22%; FB1:  64.37  42\n",
      "             SBAR: precision:  84.02%; recall:  59.92%; FB1:  69.95  169\n",
      "               VP: precision:  78.59%; recall:  86.50%; FB1:  82.36  2536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(83.76449598572702, 86.82750504371216, 85.26850208445123)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_output = [ output for sent in decoder_output for output in sent ]\n",
    "import conlleval\n",
    "true_seqs = []\n",
    "with open(os.path.join('../data','reference','dev.out')) as r:\n",
    "    for sent in conlleval.read_file(r):\n",
    "        true_seqs += sent.split()\n",
    "conlleval.evaluate(true_seqs, flat_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Conclusion\n",
    "POS tag explains how a word is used in a sentence. Chunking is a process of extracting phrases from sentence(structuring the sentence) and is a step following POS tagging. This is why there is a remarkable increase in F1 score after adding the pos tag as features. The learning outcome for us is that we can try to capitalize on existing information(features) to improve the overall performance of the system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tryout to add a second RNN ( chunker_rnn.py)\n",
    "\n",
    "We also achieves the option 2 of baseline model: a second RNN takes the character level representation as input and the output of hidden layer is concatenated with the word embedding to form the new input to the chunker RNN.\n",
    "\n",
    "### 4.1 Modify class LSTMTaggerModel\n",
    "1. Create a two LSTM layer: one for character level representation and another for chunker tagging\n",
    "2. For the LSTM layer of character level representation, the final output size of vector is set as 150 (samller than input dimension)\n",
    "3. The input dimension for LSTM layer of chunker tagging has been changed with that of word embedding + output hidden_dim_character of LSTM layer of character level representation (128 + 150 = 278)\n",
    "\n",
    "### 4.2 Results\n",
    "A F1 score of ~76.5% is obtained and is close to the implementation of option 1. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
